{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, ZeroPadding2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 1582.36it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 2415.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1293.24it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 641.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 493.56it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 548.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1774.24it/s]\n",
      "100%|██████████| 45/45 [00:00<00:00, 2752.17it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 2447.61it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 2655.10it/s]\n",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 1337.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 636.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 519.10it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1599.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 502.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 276.78it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 2206.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 766.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 184.57it/s]\n",
      "100%|██████████| 27/27 [00:00<00:00, 3007.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 900.07it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 1165.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 919.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 628.45it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1146.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 590.66it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 2186.11it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1002.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1337.58it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 901.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 669.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 493.97it/s]\n",
      "100%|██████████| 254/254 [00:00<00:00, 2180.17it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1005.83it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 458.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 320.47it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 218.77it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 2713.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 687.48it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1907.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1049.10it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 939.79it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 1701.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 994.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1003.42it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 3540.17it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1503.87it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1501.90it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2004.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1053.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1003.66it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 3205.89it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 3016.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 978.15it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 987.24it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 400.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 864.09it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 672.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.82it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1042.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1023.50it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 886.00it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 1591.05it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1352.86it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 2624.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1060.24it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 628.22it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 659.59it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 136.27it/s]\n",
      "100%|██████████| 75/75 [00:00<00:00, 2122.08it/s]\n",
      "100%|██████████| 1/1 [00:00<?, ?it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2462.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1959.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 690.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 508.71it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 989.11it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 668.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1067.52it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 639.25it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 1644.38it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 2061.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 502.49it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 200.50it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 1391.83it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 2068.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1003.90it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 849.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1005.83it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.82it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 2174.68it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 1367.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 988.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.89it/s]\n",
      "100%|██████████| 178/178 [00:00<00:00, 3236.21it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 500.93it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 508.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 476.19it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 2383.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 647.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 454.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 512.13it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 953.79it/s]\n",
      "100%|██████████| 57/57 [00:00<00:00, 1720.55it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1004.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 820.32it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 995.92it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1458.38it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 1937.71it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 3549.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 746.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1003.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1503.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 753.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 858.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 978.61it/s]\n",
      "100%|██████████| 63/63 [00:00<00:00, 1583.64it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.68it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1012.63it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1004.62it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 501.29it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 1590.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1483.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 887.87it/s]\n",
      "100%|██████████| 58/58 [00:00<00:00, 2332.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 334.26it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 2369.66it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 2089.21it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 2757.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1345.19it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 2666.44it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 3871.96it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1903.04it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2004.45it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 917.39it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1274.86it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2018.92it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1023.00it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1543.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 392.10it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = 'dataset'\n",
    "dirs = []\n",
    "training_data = []\n",
    "width, height = 13, 19\n",
    "\n",
    "# Looping direktori data training untuk diambil nama karakternya\n",
    "for char_name in sorted(os.listdir(DATADIR)):\n",
    "    dirs.append(char_name)\n",
    "\n",
    "# Looping semua image data training untuk diubah menjadi array\n",
    "for char_name in dirs:\n",
    "    path = os.path.join(DATADIR, char_name)\n",
    "    class_number = dirs.index(char_name)\n",
    "\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        try:\n",
    "            img_array = cv.imread(os.path.join(path, img), cv.IMREAD_GRAYSCALE)\n",
    "            new_array = cv.resize(img_array, (width, height))\n",
    "            training_data.append([new_array, class_number])\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "  X.append(features)\n",
    "  Y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, width, height, 1)\n",
    "\n",
    "# Tulis ke file pickle\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y.pickle\", \"wb\")\n",
    "pickle.dump(Y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "66/66 [==============================] - 4s 12ms/step - loss: 4.9635 - accuracy: 0.1004\n",
      "Epoch 2/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 4.5425 - accuracy: 0.1221\n",
      "Epoch 3/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 4.1169 - accuracy: 0.1221\n",
      "Epoch 4/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.9288 - accuracy: 0.1221\n",
      "Epoch 5/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.8075 - accuracy: 0.1221\n",
      "Epoch 6/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.7430 - accuracy: 0.1221\n",
      "Epoch 7/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.7152 - accuracy: 0.1221\n",
      "Epoch 8/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6950 - accuracy: 0.1221\n",
      "Epoch 9/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6811 - accuracy: 0.1221\n",
      "Epoch 10/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6725 - accuracy: 0.1221\n",
      "Epoch 11/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6574 - accuracy: 0.1221\n",
      "Epoch 12/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 3.6473 - accuracy: 0.1221\n",
      "Epoch 13/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 3.6354 - accuracy: 0.1221\n",
      "Epoch 14/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 3.6195 - accuracy: 0.1221\n",
      "Epoch 15/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.6065 - accuracy: 0.1225\n",
      "Epoch 16/300\n",
      "66/66 [==============================] - 1s 18ms/step - loss: 3.5858 - accuracy: 0.1230\n",
      "Epoch 17/300\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 3.5627 - accuracy: 0.1254\n",
      "Epoch 18/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 3.5386 - accuracy: 0.1259\n",
      "Epoch 19/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.5095 - accuracy: 0.1509\n",
      "Epoch 20/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.4756 - accuracy: 0.1619\n",
      "Epoch 21/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.4454 - accuracy: 0.1807\n",
      "Epoch 22/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.4049 - accuracy: 0.2028\n",
      "Epoch 23/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.3638 - accuracy: 0.2076\n",
      "Epoch 24/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.3209 - accuracy: 0.2321\n",
      "Epoch 25/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.2746 - accuracy: 0.2283\n",
      "Epoch 26/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.2302 - accuracy: 0.2456\n",
      "Epoch 27/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.1826 - accuracy: 0.2580\n",
      "Epoch 28/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.1279 - accuracy: 0.2667\n",
      "Epoch 29/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.0756 - accuracy: 0.2744\n",
      "Epoch 30/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 3.0246 - accuracy: 0.2864\n",
      "Epoch 31/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 2.9739 - accuracy: 0.2931\n",
      "Epoch 32/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.9232 - accuracy: 0.3047\n",
      "Epoch 33/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.8632 - accuracy: 0.3148\n",
      "Epoch 34/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.8136 - accuracy: 0.3248\n",
      "Epoch 35/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.7544 - accuracy: 0.3518\n",
      "Epoch 36/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.6939 - accuracy: 0.3724\n",
      "Epoch 37/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.6435 - accuracy: 0.3777\n",
      "Epoch 38/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.6026 - accuracy: 0.3936\n",
      "Epoch 39/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 2.5436 - accuracy: 0.4214\n",
      "Epoch 40/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 2.4987 - accuracy: 0.4325\n",
      "Epoch 41/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 2.4548 - accuracy: 0.4455\n",
      "Epoch 42/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.4097 - accuracy: 0.4527\n",
      "Epoch 43/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 2.3773 - accuracy: 0.4709\n",
      "Epoch 44/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.3308 - accuracy: 0.4810\n",
      "Epoch 45/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 2.2911 - accuracy: 0.4825\n",
      "Epoch 46/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 2.2492 - accuracy: 0.5050\n",
      "Epoch 47/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.2196 - accuracy: 0.4998\n",
      "Epoch 48/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 2.1787 - accuracy: 0.5113\n",
      "Epoch 49/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 2.1425 - accuracy: 0.5281\n",
      "Epoch 50/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 2.1223 - accuracy: 0.5363\n",
      "Epoch 51/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.0794 - accuracy: 0.5420\n",
      "Epoch 52/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 2.0391 - accuracy: 0.5425\n",
      "Epoch 53/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 2.0127 - accuracy: 0.5541\n",
      "Epoch 54/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.9796 - accuracy: 0.5627\n",
      "Epoch 55/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.9671 - accuracy: 0.5608\n",
      "Epoch 56/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.9246 - accuracy: 0.5762\n",
      "Epoch 57/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.8931 - accuracy: 0.5915\n",
      "Epoch 58/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.8591 - accuracy: 0.5848\n",
      "Epoch 59/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.8250 - accuracy: 0.5925\n",
      "Epoch 60/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.8013 - accuracy: 0.6026\n",
      "Epoch 61/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.7771 - accuracy: 0.6103\n",
      "Epoch 62/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.7469 - accuracy: 0.6136\n",
      "Epoch 63/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.7233 - accuracy: 0.6194\n",
      "Epoch 64/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.7109 - accuracy: 0.6170\n",
      "Epoch 65/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.6813 - accuracy: 0.6233\n",
      "Epoch 66/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.6547 - accuracy: 0.6295\n",
      "Epoch 67/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.6379 - accuracy: 0.6343\n",
      "Epoch 68/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.6090 - accuracy: 0.6386\n",
      "Epoch 69/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 1.5735 - accuracy: 0.6434\n",
      "Epoch 70/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.5597 - accuracy: 0.6487\n",
      "Epoch 71/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.5340 - accuracy: 0.6569\n",
      "Epoch 72/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.5163 - accuracy: 0.6564\n",
      "Epoch 73/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.5004 - accuracy: 0.6612\n",
      "Epoch 74/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.4816 - accuracy: 0.6684\n",
      "Epoch 75/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 1.4653 - accuracy: 0.6660\n",
      "Epoch 76/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 1.4420 - accuracy: 0.6708\n",
      "Epoch 77/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.4276 - accuracy: 0.6655\n",
      "Epoch 78/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.4016 - accuracy: 0.6756\n",
      "Epoch 79/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.3854 - accuracy: 0.6804\n",
      "Epoch 80/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.3573 - accuracy: 0.6910\n",
      "Epoch 81/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.3652 - accuracy: 0.6843\n",
      "Epoch 82/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.3339 - accuracy: 0.6915\n",
      "Epoch 83/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.3060 - accuracy: 0.6958\n",
      "Epoch 84/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 1.2911 - accuracy: 0.7001\n",
      "Epoch 85/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2750 - accuracy: 0.7054\n",
      "Epoch 86/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2602 - accuracy: 0.7112\n",
      "Epoch 87/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2490 - accuracy: 0.7078\n",
      "Epoch 88/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.2322 - accuracy: 0.7203\n",
      "Epoch 89/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 1.2141 - accuracy: 0.7170\n",
      "Epoch 90/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.2736 - accuracy: 0.6992\n",
      "Epoch 91/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 1.1810 - accuracy: 0.7266\n",
      "Epoch 92/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.1682 - accuracy: 0.7314\n",
      "Epoch 93/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.1667 - accuracy: 0.7362\n",
      "Epoch 94/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 1.1325 - accuracy: 0.7463\n",
      "Epoch 95/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.1209 - accuracy: 0.7468\n",
      "Epoch 96/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 1.1094 - accuracy: 0.7448\n",
      "Epoch 97/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.1055 - accuracy: 0.7376\n",
      "Epoch 98/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.0938 - accuracy: 0.7400\n",
      "Epoch 99/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.0711 - accuracy: 0.7525\n",
      "Epoch 100/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.0903 - accuracy: 0.7468\n",
      "Epoch 101/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.0452 - accuracy: 0.7578\n",
      "Epoch 102/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.0280 - accuracy: 0.7689\n",
      "Epoch 103/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.0150 - accuracy: 0.7650\n",
      "Epoch 104/300\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 1.0041 - accuracy: 0.7674\n",
      "Epoch 105/300\n",
      "66/66 [==============================] - 1s 17ms/step - loss: 0.9898 - accuracy: 0.7698\n",
      "Epoch 106/300\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.9831 - accuracy: 0.7669\n",
      "Epoch 107/300\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.9773 - accuracy: 0.7780\n",
      "Epoch 108/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.9563 - accuracy: 0.7785\n",
      "Epoch 109/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.9459 - accuracy: 0.7746\n",
      "Epoch 110/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.9343 - accuracy: 0.7847\n",
      "Epoch 111/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.9481 - accuracy: 0.7713\n",
      "Epoch 112/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.9208 - accuracy: 0.7842\n",
      "Epoch 113/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8947 - accuracy: 0.7866\n",
      "Epoch 114/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8958 - accuracy: 0.7847\n",
      "Epoch 115/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8813 - accuracy: 0.7914\n",
      "Epoch 116/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8584 - accuracy: 0.8001\n",
      "Epoch 117/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8575 - accuracy: 0.8006\n",
      "Epoch 118/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.8456 - accuracy: 0.8001\n",
      "Epoch 119/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8351 - accuracy: 0.8044\n",
      "Epoch 120/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.8306 - accuracy: 0.8068\n",
      "Epoch 121/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.8082 - accuracy: 0.8073\n",
      "Epoch 122/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8074 - accuracy: 0.8068\n",
      "Epoch 123/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8003 - accuracy: 0.8107\n",
      "Epoch 124/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.7950 - accuracy: 0.8083\n",
      "Epoch 125/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7749 - accuracy: 0.8145\n",
      "Epoch 126/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.8036 - accuracy: 0.8049\n",
      "Epoch 127/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7637 - accuracy: 0.8150\n",
      "Epoch 128/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7515 - accuracy: 0.8184\n",
      "Epoch 129/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.7431 - accuracy: 0.8222\n",
      "Epoch 130/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7318 - accuracy: 0.8270\n",
      "Epoch 131/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7240 - accuracy: 0.8251\n",
      "Epoch 132/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7137 - accuracy: 0.8275\n",
      "Epoch 133/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.7033 - accuracy: 0.8309\n",
      "Epoch 134/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.7142 - accuracy: 0.8265\n",
      "Epoch 135/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6947 - accuracy: 0.8270\n",
      "Epoch 136/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.6990 - accuracy: 0.8347\n",
      "Epoch 137/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.6755 - accuracy: 0.8400\n",
      "Epoch 138/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.6780 - accuracy: 0.8414\n",
      "Epoch 139/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.6754 - accuracy: 0.8390\n",
      "Epoch 140/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6535 - accuracy: 0.8438\n",
      "Epoch 141/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.6504 - accuracy: 0.8462\n",
      "Epoch 142/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6412 - accuracy: 0.8462\n",
      "Epoch 143/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.6404 - accuracy: 0.8448\n",
      "Epoch 144/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.6266 - accuracy: 0.8486\n",
      "Epoch 145/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6259 - accuracy: 0.8515\n",
      "Epoch 146/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.6101 - accuracy: 0.8520\n",
      "Epoch 147/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6121 - accuracy: 0.8534\n",
      "Epoch 148/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5964 - accuracy: 0.8563\n",
      "Epoch 149/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.6427 - accuracy: 0.8462\n",
      "Epoch 150/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.5849 - accuracy: 0.8626\n",
      "Epoch 151/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5958 - accuracy: 0.8568\n",
      "Epoch 152/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.5766 - accuracy: 0.8645\n",
      "Epoch 153/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5666 - accuracy: 0.8645\n",
      "Epoch 154/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5581 - accuracy: 0.8712\n",
      "Epoch 155/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5622 - accuracy: 0.8659\n",
      "Epoch 156/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.5662 - accuracy: 0.8597\n",
      "Epoch 157/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5450 - accuracy: 0.8707\n",
      "Epoch 158/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5459 - accuracy: 0.8659\n",
      "Epoch 159/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5327 - accuracy: 0.8727\n",
      "Epoch 160/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.5324 - accuracy: 0.8770\n",
      "Epoch 161/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5205 - accuracy: 0.8741\n",
      "Epoch 162/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5156 - accuracy: 0.8727\n",
      "Epoch 163/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5069 - accuracy: 0.8760\n",
      "Epoch 164/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.5119 - accuracy: 0.8755\n",
      "Epoch 165/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.5057 - accuracy: 0.8779\n",
      "Epoch 166/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5092 - accuracy: 0.8746\n",
      "Epoch 167/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.4950 - accuracy: 0.8799\n",
      "Epoch 168/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.4842 - accuracy: 0.8794\n",
      "Epoch 169/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.5208 - accuracy: 0.8703\n",
      "Epoch 170/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.4755 - accuracy: 0.8852\n",
      "Epoch 171/300\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.4702 - accuracy: 0.8847\n",
      "Epoch 172/300\n",
      "66/66 [==============================] - 1s 15ms/step - loss: 0.4771 - accuracy: 0.8856\n",
      "Epoch 173/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.4640 - accuracy: 0.8876\n",
      "Epoch 174/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.4581 - accuracy: 0.8861\n",
      "Epoch 175/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.4550 - accuracy: 0.8890\n",
      "Epoch 176/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.4452 - accuracy: 0.8952\n",
      "Epoch 177/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.4452 - accuracy: 0.8895\n",
      "Epoch 178/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.4389 - accuracy: 0.8952\n",
      "Epoch 179/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.4299 - accuracy: 0.8938\n",
      "Epoch 180/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.4340 - accuracy: 0.8972\n",
      "Epoch 181/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.4258 - accuracy: 0.8909\n",
      "Epoch 182/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.4243 - accuracy: 0.8981\n",
      "Epoch 183/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.4340 - accuracy: 0.8943\n",
      "Epoch 184/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.4162 - accuracy: 0.8948\n",
      "Epoch 185/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.4098 - accuracy: 0.9029\n",
      "Epoch 186/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.4088 - accuracy: 0.8986\n",
      "Epoch 187/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.3999 - accuracy: 0.9015\n",
      "Epoch 188/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3963 - accuracy: 0.9039\n",
      "Epoch 189/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3939 - accuracy: 0.9034\n",
      "Epoch 190/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.3990 - accuracy: 0.9010\n",
      "Epoch 191/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3865 - accuracy: 0.9029\n",
      "Epoch 192/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3814 - accuracy: 0.9000\n",
      "Epoch 193/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.4001 - accuracy: 0.8972\n",
      "Epoch 194/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3761 - accuracy: 0.9077\n",
      "Epoch 195/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3750 - accuracy: 0.9044\n",
      "Epoch 196/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3707 - accuracy: 0.9106\n",
      "Epoch 197/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3630 - accuracy: 0.9101\n",
      "Epoch 198/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.3575 - accuracy: 0.9145\n",
      "Epoch 199/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.3609 - accuracy: 0.9140\n",
      "Epoch 200/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.3555 - accuracy: 0.9116\n",
      "Epoch 201/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.3496 - accuracy: 0.9125\n",
      "Epoch 202/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3493 - accuracy: 0.9130\n",
      "Epoch 203/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.3393 - accuracy: 0.9183\n",
      "Epoch 204/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3383 - accuracy: 0.9198\n",
      "Epoch 205/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.3403 - accuracy: 0.9183\n",
      "Epoch 206/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3363 - accuracy: 0.9198\n",
      "Epoch 207/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3598 - accuracy: 0.9101\n",
      "Epoch 208/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3260 - accuracy: 0.9207\n",
      "Epoch 209/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.3258 - accuracy: 0.9217\n",
      "Epoch 210/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.3172 - accuracy: 0.9226\n",
      "Epoch 211/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.3148 - accuracy: 0.9231\n",
      "Epoch 212/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3205 - accuracy: 0.9198\n",
      "Epoch 213/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3134 - accuracy: 0.9231\n",
      "Epoch 214/300\n",
      "66/66 [==============================] - 1s 9ms/step - loss: 0.3072 - accuracy: 0.9226\n",
      "Epoch 215/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.3019 - accuracy: 0.9279\n",
      "Epoch 216/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.3037 - accuracy: 0.9289\n",
      "Epoch 217/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.2940 - accuracy: 0.9298\n",
      "Epoch 218/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.3011 - accuracy: 0.9260\n",
      "Epoch 219/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2917 - accuracy: 0.9337\n",
      "Epoch 220/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2912 - accuracy: 0.9351\n",
      "Epoch 221/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2831 - accuracy: 0.9332\n",
      "Epoch 222/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2875 - accuracy: 0.9303\n",
      "Epoch 223/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2966 - accuracy: 0.9284\n",
      "Epoch 224/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.3171 - accuracy: 0.9246\n",
      "Epoch 225/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2745 - accuracy: 0.9356\n",
      "Epoch 226/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.3296 - accuracy: 0.9130\n",
      "Epoch 227/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2751 - accuracy: 0.9361\n",
      "Epoch 228/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2722 - accuracy: 0.9366\n",
      "Epoch 229/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2668 - accuracy: 0.9385\n",
      "Epoch 230/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.4021 - accuracy: 0.8928\n",
      "Epoch 231/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2748 - accuracy: 0.9318\n",
      "Epoch 232/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2585 - accuracy: 0.9404\n",
      "Epoch 233/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2537 - accuracy: 0.9443\n",
      "Epoch 234/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2507 - accuracy: 0.9423\n",
      "Epoch 235/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2505 - accuracy: 0.9433\n",
      "Epoch 236/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2530 - accuracy: 0.9438\n",
      "Epoch 237/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2490 - accuracy: 0.9423\n",
      "Epoch 238/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2422 - accuracy: 0.9471\n",
      "Epoch 239/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2397 - accuracy: 0.9510\n",
      "Epoch 240/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2370 - accuracy: 0.9457\n",
      "Epoch 241/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2365 - accuracy: 0.9486\n",
      "Epoch 242/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2379 - accuracy: 0.9471\n",
      "Epoch 243/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2623 - accuracy: 0.9366\n",
      "Epoch 244/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2325 - accuracy: 0.9476\n",
      "Epoch 245/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2879 - accuracy: 0.9270\n",
      "Epoch 246/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2278 - accuracy: 0.9476\n",
      "Epoch 247/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2554 - accuracy: 0.9361\n",
      "Epoch 248/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.2229 - accuracy: 0.9481\n",
      "Epoch 249/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2199 - accuracy: 0.9529\n",
      "Epoch 250/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2581 - accuracy: 0.9375\n",
      "Epoch 251/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2173 - accuracy: 0.9543\n",
      "Epoch 252/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2145 - accuracy: 0.9510\n",
      "Epoch 253/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2135 - accuracy: 0.9553\n",
      "Epoch 254/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.2122 - accuracy: 0.9515\n",
      "Epoch 255/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2096 - accuracy: 0.9558\n",
      "Epoch 256/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2373 - accuracy: 0.9443\n",
      "Epoch 257/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.2080 - accuracy: 0.9558\n",
      "Epoch 258/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2501 - accuracy: 0.9356\n",
      "Epoch 259/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.2021 - accuracy: 0.9568\n",
      "Epoch 260/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.2004 - accuracy: 0.9548\n",
      "Epoch 261/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1971 - accuracy: 0.9582\n",
      "Epoch 262/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1997 - accuracy: 0.9572\n",
      "Epoch 263/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.1969 - accuracy: 0.9587\n",
      "Epoch 264/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.2128 - accuracy: 0.9519\n",
      "Epoch 265/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1922 - accuracy: 0.9568\n",
      "Epoch 266/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1875 - accuracy: 0.9587\n",
      "Epoch 267/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.2109 - accuracy: 0.9534\n",
      "Epoch 268/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1946 - accuracy: 0.9582\n",
      "Epoch 269/300\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.1952 - accuracy: 0.9529\n",
      "Epoch 270/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1870 - accuracy: 0.9587\n",
      "Epoch 271/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1841 - accuracy: 0.9611\n",
      "Epoch 272/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1812 - accuracy: 0.9635\n",
      "Epoch 273/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1783 - accuracy: 0.9654\n",
      "Epoch 274/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1800 - accuracy: 0.9606\n",
      "Epoch 275/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1758 - accuracy: 0.9630\n",
      "Epoch 276/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1740 - accuracy: 0.9640\n",
      "Epoch 277/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1719 - accuracy: 0.9630\n",
      "Epoch 278/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1684 - accuracy: 0.9630\n",
      "Epoch 279/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1681 - accuracy: 0.9601\n",
      "Epoch 280/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1701 - accuracy: 0.9620\n",
      "Epoch 281/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1668 - accuracy: 0.9640\n",
      "Epoch 282/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1673 - accuracy: 0.9644\n",
      "Epoch 283/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1638 - accuracy: 0.9649\n",
      "Epoch 284/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.1885 - accuracy: 0.9582\n",
      "Epoch 285/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1620 - accuracy: 0.9640\n",
      "Epoch 286/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1601 - accuracy: 0.9640\n",
      "Epoch 287/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1621 - accuracy: 0.9654\n",
      "Epoch 288/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1540 - accuracy: 0.9659\n",
      "Epoch 289/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1592 - accuracy: 0.9620\n",
      "Epoch 290/300\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.1535 - accuracy: 0.9697\n",
      "Epoch 291/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1469 - accuracy: 0.9688\n",
      "Epoch 292/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1507 - accuracy: 0.9697\n",
      "Epoch 293/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1527 - accuracy: 0.9664\n",
      "Epoch 294/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1494 - accuracy: 0.9683\n",
      "Epoch 295/300\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.1458 - accuracy: 0.9649\n",
      "Epoch 296/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1457 - accuracy: 0.9688\n",
      "Epoch 297/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1494 - accuracy: 0.9644\n",
      "Epoch 298/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1474 - accuracy: 0.9659\n",
      "Epoch 299/300\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.1397 - accuracy: 0.9697\n",
      "Epoch 300/300\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.1410 - accuracy: 0.9692\n",
      "INFO:tensorflow:Assets written to: alphabet.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: alphabet.model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Load file pickle\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Y.pickle\", \"rb\")\n",
    "Y = pickle.load(pickle_in)\n",
    "Y = to_categorical(Y)\n",
    "X = X / 255.0\n",
    "# Input layer\n",
    "inputs = Input(shape=(width, height, 1))\n",
    "conv_layer = ZeroPadding2D(padding=(2, 2))(inputs)\n",
    "conv_layer = Conv2D(16, (5, 5), strides=(1, 1), activation='relu')(conv_layer)\n",
    "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
    "conv_layer = Conv2D(32, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
    "conv_layer = Conv2D(32, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
    "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
    "\n",
    "flaten = Flatten()(conv_layer)\n",
    "fc_layer = Dense(256, activation='relu')(flaten)\n",
    "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(len(dirs), activation='softmax')(fc_layer)\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=len(dirs)*2, verbose=1)\n",
    "model.save('alphabet.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
