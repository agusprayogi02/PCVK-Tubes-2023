{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense, ZeroPadding2D\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:00<00:00, 401.04it/s]\n",
      "100%|██████████| 24/24 [00:00<00:00, 2406.43it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2006.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 335.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 890.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 940.85it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 334.13it/s]\n",
      "100%|██████████| 45/45 [00:00<00:00, 1879.82it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 591.93it/s]\n",
      "100%|██████████| 7/7 [00:00<00:00, 1754.41it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1336.62it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.41it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.17it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1618.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 363.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.46it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 1840.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 516.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "  0%|          | 0/27 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [00:00<00:00, 1139.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 707.78it/s]\n",
      "100%|██████████| 6/6 [00:00<00:00, 2005.88it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 388.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 1307.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1064.81it/s]\n",
      "100%|██████████| 13/13 [00:00<00:00, 1448.19it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1002.54it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1367.67it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1003.30it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 69.86it/s]\n",
      "100%|██████████| 254/254 [00:00<00:00, 1179.14it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 559.91it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 567.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 469.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1061.18it/s]\n",
      "100%|██████████| 46/46 [00:00<00:00, 1356.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 653.83it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1005.19it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.53it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.59it/s]\n",
      "100%|██████████| 15/15 [00:00<00:00, 1503.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 2049.63it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1002.54it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1461.43it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 400.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.74it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 997.46it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 799.01it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1504.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 420.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 400.05it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2002.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 500.63it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 42.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1009.46it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1001.86it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.29it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 1837.70it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1503.69it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 661.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.11it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 2279.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 367.42it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.23it/s]\n",
      "100%|██████████| 75/75 [00:00<00:00, 1373.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.22it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 668.20it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 848.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 616.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 998.41it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1059.97it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 1002.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 1790.39it/s]\n",
      "100%|██████████| 82/82 [00:00<00:00, 1678.00it/s]\n",
      "100%|██████████| 37/37 [00:00<00:00, 1766.65it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 562.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 877.29it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 468.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.35it/s]\n",
      "100%|██████████| 49/49 [00:00<00:00, 1445.00it/s]\n",
      "100%|██████████| 33/33 [00:00<00:00, 1741.47it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1003.66it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 996.98it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 500.57it/s]\n",
      "100%|██████████| 100/100 [00:00<00:00, 946.09it/s]\n",
      "100%|██████████| 11/11 [00:00<00:00, 1102.52it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 786.48it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.11it/s]\n",
      "100%|██████████| 178/178 [00:00<00:00, 1416.44it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.03it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 753.69it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 502.01it/s]\n",
      "100%|██████████| 89/89 [00:00<00:00, 1643.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 334.18it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1001.27it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 968.55it/s]\n",
      "100%|██████████| 57/57 [00:00<00:00, 1659.61it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 671.73it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.66it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2523.65it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 500.60it/s]\n",
      "100%|██████████| 81/81 [00:00<00:00, 1505.49it/s]\n",
      "100%|██████████| 14/14 [00:00<00:00, 1667.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 965.54it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 473.77it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1212.23it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 278.58it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 501.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.42it/s]\n",
      "100%|██████████| 63/63 [00:00<00:00, 1858.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 495.78it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1068.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 866.59it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 508.43it/s]\n",
      "100%|██████████| 102/102 [00:00<00:00, 2322.28it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1093.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.86it/s]\n",
      "100%|██████████| 58/58 [00:00<00:00, 3064.16it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 250.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 496.78it/s]\n",
      "100%|██████████| 25/25 [00:00<00:00, 2279.07it/s]\n",
      "100%|██████████| 22/22 [00:00<00:00, 2757.60it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1000.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.70it/s]\n",
      "100%|██████████| 8/8 [00:00<00:00, 2652.52it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 2049.75it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 2003.97it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1336.72it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 979.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1002.94it/s]\n",
      "100%|██████████| 4/4 [00:00<00:00, 1085.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 645.18it/s]\n",
      "100%|██████████| 3/3 [00:00<00:00, 1503.51it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 1485.24it/s]\n"
     ]
    }
   ],
   "source": [
    "DATADIR = 'dataset'\n",
    "dirs = []\n",
    "training_data = []\n",
    "width, height = 13, 19\n",
    "\n",
    "# Looping direktori data training untuk diambil nama karakternya\n",
    "for char_name in sorted(os.listdir(DATADIR)):\n",
    "    dirs.append(char_name)\n",
    "\n",
    "# Looping semua image data training untuk diubah menjadi array\n",
    "for char_name in dirs:\n",
    "    path = os.path.join(DATADIR, char_name)\n",
    "    class_number = dirs.index(char_name)\n",
    "\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "        try:\n",
    "            img_array = cv.imread(os.path.join(path, img), cv.IMREAD_GRAYSCALE)\n",
    "            new_array = cv.resize(img_array, (width, height))\n",
    "            training_data.append([new_array, class_number])\n",
    "        except Exception as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.shuffle(training_data)\n",
    "\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "  X.append(features)\n",
    "  Y.append(label)\n",
    "\n",
    "X = np.array(X).reshape(-1, width, height, 1)\n",
    "\n",
    "# Tulis ke file pickle\n",
    "pickle_out = open(\"X.pickle\", \"wb\")\n",
    "pickle.dump(X, pickle_out)\n",
    "pickle_out.close()\n",
    "\n",
    "pickle_out = open(\"Y.pickle\", \"wb\")\n",
    "pickle.dump(Y, pickle_out)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "66/66 [==============================] - 3s 11ms/step - loss: 4.9825 - accuracy: 0.0346\n",
      "Epoch 2/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 4.5898 - accuracy: 0.1221\n",
      "Epoch 3/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 4.0295 - accuracy: 0.1221\n",
      "Epoch 4/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.8307 - accuracy: 0.1221\n",
      "Epoch 5/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 3.7487 - accuracy: 0.1221\n",
      "Epoch 6/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.7119 - accuracy: 0.1221\n",
      "Epoch 7/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6935 - accuracy: 0.1221\n",
      "Epoch 8/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6792 - accuracy: 0.1221\n",
      "Epoch 9/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6667 - accuracy: 0.1221\n",
      "Epoch 10/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6517 - accuracy: 0.1221\n",
      "Epoch 11/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.6357 - accuracy: 0.1225\n",
      "Epoch 12/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 3.6162 - accuracy: 0.1221\n",
      "Epoch 13/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.5890 - accuracy: 0.1254\n",
      "Epoch 14/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.5567 - accuracy: 0.1360\n",
      "Epoch 15/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.5119 - accuracy: 0.1682\n",
      "Epoch 16/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.4673 - accuracy: 0.1864\n",
      "Epoch 17/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.4244 - accuracy: 0.1903\n",
      "Epoch 18/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 3.3906 - accuracy: 0.1908\n",
      "Epoch 19/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.3566 - accuracy: 0.1985\n",
      "Epoch 20/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.3130 - accuracy: 0.1989\n",
      "Epoch 21/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.2736 - accuracy: 0.2090\n",
      "Epoch 22/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 3.2303 - accuracy: 0.2230\n",
      "Epoch 23/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.1879 - accuracy: 0.2489\n",
      "Epoch 24/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 3.1385 - accuracy: 0.2778\n",
      "Epoch 25/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.0816 - accuracy: 0.2854\n",
      "Epoch 26/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 3.0251 - accuracy: 0.2859\n",
      "Epoch 27/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.9483 - accuracy: 0.3133\n",
      "Epoch 28/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.8790 - accuracy: 0.3056\n",
      "Epoch 29/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.8070 - accuracy: 0.3383\n",
      "Epoch 30/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.7426 - accuracy: 0.3441\n",
      "Epoch 31/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.6936 - accuracy: 0.3575\n",
      "Epoch 32/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.6291 - accuracy: 0.3681\n",
      "Epoch 33/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.5752 - accuracy: 0.3955\n",
      "Epoch 34/150\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 2.5268 - accuracy: 0.4109\n",
      "Epoch 35/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.4771 - accuracy: 0.4176\n",
      "Epoch 36/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.4346 - accuracy: 0.4137\n",
      "Epoch 37/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.3854 - accuracy: 0.4416\n",
      "Epoch 38/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 2.3351 - accuracy: 0.4589\n",
      "Epoch 39/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.2905 - accuracy: 0.4801\n",
      "Epoch 40/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.2452 - accuracy: 0.4805\n",
      "Epoch 41/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.2052 - accuracy: 0.4858\n",
      "Epoch 42/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.1594 - accuracy: 0.5070\n",
      "Epoch 43/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 2.1157 - accuracy: 0.5108\n",
      "Epoch 44/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.0721 - accuracy: 0.5209\n",
      "Epoch 45/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 2.0434 - accuracy: 0.5204\n",
      "Epoch 46/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.9989 - accuracy: 0.5420\n",
      "Epoch 47/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.9567 - accuracy: 0.5613\n",
      "Epoch 48/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.9258 - accuracy: 0.5627\n",
      "Epoch 49/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.8876 - accuracy: 0.5771\n",
      "Epoch 50/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.8570 - accuracy: 0.5834\n",
      "Epoch 51/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.8161 - accuracy: 0.5930\n",
      "Epoch 52/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.7961 - accuracy: 0.5963\n",
      "Epoch 53/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.7593 - accuracy: 0.6002\n",
      "Epoch 54/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.7200 - accuracy: 0.6156\n",
      "Epoch 55/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.6998 - accuracy: 0.6185\n",
      "Epoch 56/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.6617 - accuracy: 0.6266\n",
      "Epoch 57/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.6446 - accuracy: 0.6276\n",
      "Epoch 58/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.6150 - accuracy: 0.6348\n",
      "Epoch 59/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.5851 - accuracy: 0.6382\n",
      "Epoch 60/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.5626 - accuracy: 0.6458\n",
      "Epoch 61/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.5512 - accuracy: 0.6516\n",
      "Epoch 62/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.5418 - accuracy: 0.6386\n",
      "Epoch 63/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.4946 - accuracy: 0.6631\n",
      "Epoch 64/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.4668 - accuracy: 0.6617\n",
      "Epoch 65/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.4441 - accuracy: 0.6761\n",
      "Epoch 66/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.4228 - accuracy: 0.6752\n",
      "Epoch 67/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.4167 - accuracy: 0.6713\n",
      "Epoch 68/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.3862 - accuracy: 0.6857\n",
      "Epoch 69/150\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 1.3620 - accuracy: 0.6800\n",
      "Epoch 70/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.3442 - accuracy: 0.6848\n",
      "Epoch 71/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.3315 - accuracy: 0.6905\n",
      "Epoch 72/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.3121 - accuracy: 0.6925\n",
      "Epoch 73/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.2949 - accuracy: 0.6949\n",
      "Epoch 74/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2733 - accuracy: 0.7011\n",
      "Epoch 75/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2576 - accuracy: 0.7011\n",
      "Epoch 76/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2358 - accuracy: 0.7098\n",
      "Epoch 77/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2199 - accuracy: 0.7155\n",
      "Epoch 78/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.2100 - accuracy: 0.7112\n",
      "Epoch 79/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.1820 - accuracy: 0.7213\n",
      "Epoch 80/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.1693 - accuracy: 0.7227\n",
      "Epoch 81/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.1647 - accuracy: 0.7165\n",
      "Epoch 82/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.1341 - accuracy: 0.7299\n",
      "Epoch 83/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 1.1211 - accuracy: 0.7352\n",
      "Epoch 84/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.1031 - accuracy: 0.7395\n",
      "Epoch 85/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.0960 - accuracy: 0.7347\n",
      "Epoch 86/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.0712 - accuracy: 0.7405\n",
      "Epoch 87/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.0567 - accuracy: 0.7458\n",
      "Epoch 88/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 1.0581 - accuracy: 0.7482\n",
      "Epoch 89/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 1.0321 - accuracy: 0.7439\n",
      "Epoch 90/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.0329 - accuracy: 0.7439\n",
      "Epoch 91/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 1.0054 - accuracy: 0.7511\n",
      "Epoch 92/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.9931 - accuracy: 0.7549\n",
      "Epoch 93/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.9798 - accuracy: 0.7554\n",
      "Epoch 94/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.9679 - accuracy: 0.7578\n",
      "Epoch 95/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.9923 - accuracy: 0.7444\n",
      "Epoch 96/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.9393 - accuracy: 0.7597\n",
      "Epoch 97/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.9265 - accuracy: 0.7674\n",
      "Epoch 98/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.9205 - accuracy: 0.7684\n",
      "Epoch 99/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.9047 - accuracy: 0.7693\n",
      "Epoch 100/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.8925 - accuracy: 0.7741\n",
      "Epoch 101/150\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.8913 - accuracy: 0.7713\n",
      "Epoch 102/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8727 - accuracy: 0.7713\n",
      "Epoch 103/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8606 - accuracy: 0.7775\n",
      "Epoch 104/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.9034 - accuracy: 0.7674\n",
      "Epoch 105/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8423 - accuracy: 0.7818\n",
      "Epoch 106/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8405 - accuracy: 0.7818\n",
      "Epoch 107/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8205 - accuracy: 0.7876\n",
      "Epoch 108/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.8120 - accuracy: 0.7905\n",
      "Epoch 109/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8101 - accuracy: 0.7862\n",
      "Epoch 110/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8035 - accuracy: 0.7905\n",
      "Epoch 111/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.7995 - accuracy: 0.7914\n",
      "Epoch 112/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.8552 - accuracy: 0.7713\n",
      "Epoch 113/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7613 - accuracy: 0.8087\n",
      "Epoch 114/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7556 - accuracy: 0.8030\n",
      "Epoch 115/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.7420 - accuracy: 0.8092\n",
      "Epoch 116/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.7319 - accuracy: 0.8087\n",
      "Epoch 117/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.7247 - accuracy: 0.8150\n",
      "Epoch 118/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.7240 - accuracy: 0.8073\n",
      "Epoch 119/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.7093 - accuracy: 0.8126\n",
      "Epoch 120/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7017 - accuracy: 0.8150\n",
      "Epoch 121/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.7049 - accuracy: 0.8131\n",
      "Epoch 122/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6883 - accuracy: 0.8140\n",
      "Epoch 123/150\n",
      "66/66 [==============================] - 1s 16ms/step - loss: 0.6775 - accuracy: 0.8227\n",
      "Epoch 124/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6764 - accuracy: 0.8241\n",
      "Epoch 125/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.7025 - accuracy: 0.8145\n",
      "Epoch 126/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.6514 - accuracy: 0.8361\n",
      "Epoch 127/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.6696 - accuracy: 0.8294\n",
      "Epoch 128/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6361 - accuracy: 0.8357\n",
      "Epoch 129/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6347 - accuracy: 0.8385\n",
      "Epoch 130/150\n",
      "66/66 [==============================] - 1s 14ms/step - loss: 0.6254 - accuracy: 0.8419\n",
      "Epoch 131/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6184 - accuracy: 0.8429\n",
      "Epoch 132/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6121 - accuracy: 0.8477\n",
      "Epoch 133/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.6026 - accuracy: 0.8467\n",
      "Epoch 134/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.5960 - accuracy: 0.8472\n",
      "Epoch 135/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5833 - accuracy: 0.8491\n",
      "Epoch 136/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5856 - accuracy: 0.8506\n",
      "Epoch 137/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.5736 - accuracy: 0.8597\n",
      "Epoch 138/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5682 - accuracy: 0.8534\n",
      "Epoch 139/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5618 - accuracy: 0.8573\n",
      "Epoch 140/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5582 - accuracy: 0.8563\n",
      "Epoch 141/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5522 - accuracy: 0.8602\n",
      "Epoch 142/150\n",
      "66/66 [==============================] - 1s 10ms/step - loss: 0.5588 - accuracy: 0.8563\n",
      "Epoch 143/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5416 - accuracy: 0.8630\n",
      "Epoch 144/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.5480 - accuracy: 0.8573\n",
      "Epoch 145/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5315 - accuracy: 0.8587\n",
      "Epoch 146/150\n",
      "66/66 [==============================] - 1s 13ms/step - loss: 0.5179 - accuracy: 0.8679\n",
      "Epoch 147/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5121 - accuracy: 0.8707\n",
      "Epoch 148/150\n",
      "66/66 [==============================] - 1s 11ms/step - loss: 0.5075 - accuracy: 0.8640\n",
      "Epoch 149/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5002 - accuracy: 0.8727\n",
      "Epoch 150/150\n",
      "66/66 [==============================] - 1s 12ms/step - loss: 0.5030 - accuracy: 0.8683\n",
      "INFO:tensorflow:Assets written to: alphabet.model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: alphabet.model\\assets\n"
     ]
    }
   ],
   "source": [
    "# Load file pickle\n",
    "pickle_in = open(\"X.pickle\", \"rb\")\n",
    "X = pickle.load(pickle_in)\n",
    "\n",
    "pickle_in = open(\"Y.pickle\", \"rb\")\n",
    "Y = pickle.load(pickle_in)\n",
    "Y = to_categorical(Y)\n",
    "X = X / 255.0\n",
    "# Input layer\n",
    "inputs = Input(shape=(width, height, 1))\n",
    "conv_layer = ZeroPadding2D(padding=(2, 2))(inputs)\n",
    "conv_layer = Conv2D(16, (5, 5), strides=(1, 1), activation='relu')(conv_layer)\n",
    "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
    "conv_layer = Conv2D(32, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
    "conv_layer = Conv2D(32, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
    "conv_layer = MaxPooling2D((2, 2))(conv_layer)\n",
    "# conv_layer = Conv2D(64, (3, 3), strides=(1, 1), activation='relu')(conv_layer)\n",
    "\n",
    "flaten = Flatten()(conv_layer)\n",
    "fc_layer = Dense(256, activation='relu')(flaten)\n",
    "fc_layer = Dense(64, activation='relu')(fc_layer)\n",
    "\n",
    "# Output layer\n",
    "outputs = Dense(len(dirs), activation='softmax')(fc_layer)\n",
    "adam = Adam(learning_rate=0.0001)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(optimizer=adam, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X, Y, epochs=len(dirs), verbose=1)\n",
    "model.save('alphabet.model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
